{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read predictions CNN\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CNN model found: 1584291022619663_inceptionresnetv2_no_ceil\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro_avg-precision</th>\n",
       "      <th>macro_avg-recall</th>\n",
       "      <th>macro_avg-f1-score</th>\n",
       "      <th>macro_avg-support</th>\n",
       "      <th>weighted_avg-precision</th>\n",
       "      <th>weighted_avg-recall</th>\n",
       "      <th>weighted_avg-f1-score</th>\n",
       "      <th>weighted_avg-support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.934995</th>\n",
       "      <td>0.939045</td>\n",
       "      <td>0.947362</td>\n",
       "      <td>0.941528</td>\n",
       "      <td>923</td>\n",
       "      <td>0.938303</td>\n",
       "      <td>0.934995</td>\n",
       "      <td>0.934377</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          macro_avg-precision  macro_avg-recall  macro_avg-f1-score  \\\n",
       "accuracy                                                              \n",
       "0.934995             0.939045          0.947362            0.941528   \n",
       "\n",
       "          macro_avg-support  weighted_avg-precision  weighted_avg-recall  \\\n",
       "accuracy                                                                   \n",
       "0.934995                923                0.938303             0.934995   \n",
       "\n",
       "          weighted_avg-f1-score  weighted_avg-support  \n",
       "accuracy                                               \n",
       "0.934995               0.934377                   923  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer, scale\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "from auxiliary_functions import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##############################################################\n",
    "# Directories, files, parameters\n",
    "##############################################################\n",
    "plots_dir = \"plots\"\n",
    "PATH = \"results/\"\n",
    "feat_file='cloud_features.csv'\n",
    "\n",
    "parameters_rf = {'n_estimators':list(range(100,1600,100))}\n",
    "\n",
    "##############################################################\n",
    "# Obtaining best CNN execution (in validation set)\n",
    "##############################################################\n",
    "\n",
    "summary_files = [each for each in os.listdir(PATH) if each.endswith('_summary_acc.csv')]\n",
    "\n",
    "# Generating dataframe with all summary files. New columns with file name, model name and set name (train,valid,test)\n",
    "df = pd.concat((pd.read_csv(os.path.join(PATH, f)).assign(file = f).assign(model = re.search('[0-9]_+(.+?)_summary_acc.csv', f).group(1).split(\"_\")[0]).\n",
    "                assign(set = re.search('[0-9]_+(.+?)_summary_acc.csv', f.replace(\"no_ceil_\", \"\")).group(1).split(\"_\")[1]) for f in summary_files))\n",
    "\n",
    "# Extracting validation results to find best execution\n",
    "df_val = df[df[\"set\"] == \"valid\"]\n",
    "best_exec_acc_val = df_val[df_val[\"accuracy\"] == max(df_val[\"accuracy\"])]\n",
    "file_best_exec = best_exec_acc_val[\"file\"][0]\n",
    "file_best_exec_id = re.search('(.+?)_[a-z]+_summary_acc.csv', file_best_exec).group(1)\n",
    "\n",
    "##############################################################\n",
    "# Reading indices of the best CNN execution\n",
    "##############################################################\n",
    "# Reading indices of the best CNN execution\n",
    "indices_file = file_best_exec.replace(\"valid_summary_acc.csv\", \"indices.pickle\")\n",
    "with open(os.path.join(PATH,indices_file), 'rb') as f:\n",
    "    in_train, in_valid, in_test  = pickle.load(f)\n",
    "\n",
    "##############################################################\n",
    "# Reading predictions of the best CNN execution\n",
    "##############################################################\n",
    "# Reading images\n",
    "img_file='images.npz'\n",
    "file_dir = \"data/\"\n",
    "images = np.load('%s/%s' % (file_dir, img_file), 'r', True)['arr_0']\n",
    "img_train, img_test, img_valid = images[in_train], images[in_test], images[in_valid]\n",
    "\n",
    "# Reading predictions of the best CNN execution\n",
    "preds_file = file_best_exec.replace(\"valid_summary_acc.csv\", \"preds.csv\")\n",
    "preds_cnn_train = pd.read_csv(os.path.join(PATH, \"%s_train_preds.csv\" % file_best_exec_id), index_col=0)\n",
    "preds_cnn_test = pd.read_csv(os.path.join(PATH, \"%s_test_preds.csv\" % file_best_exec_id), index_col=0)\n",
    "preds_cnn_valid = pd.read_csv(os.path.join(PATH, \"%s_valid_preds.csv\" % file_best_exec_id), index_col=0)\n",
    "\n",
    "# Deleting observation column\n",
    "del preds_cnn_train[\"obs\"]\n",
    "del preds_cnn_test[\"obs\"]\n",
    "del preds_cnn_valid[\"obs\"]\n",
    "\n",
    "test_summary_data_cnn = pd.read_csv(os.path.join(PATH, \"%s_test_summary_acc.csv\" % file_best_exec_id), index_col=0)\n",
    "print(\"Best CNN model found: %s\" % file_best_exec_id)\n",
    "display(test_summary_data_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Obtaining ceil features and estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining ceil features\n",
    "features = pd.read_csv('%s/%s' % (\"data\" , feat_file), sep=';', decimal=',')\n",
    "\n",
    "# Obtaining y vector\n",
    "cloud_type = np.array(features['cloud.type'])\n",
    "encoder = LabelBinarizer()\n",
    "cloud_encoded = encoder.fit_transform(cloud_type)\n",
    "y_train, y_test, y_valid = cloud_encoded[in_train], cloud_encoded[in_test], cloud_encoded[in_valid]\n",
    "y_test_dec = encoder.inverse_transform(y_test)\n",
    "\n",
    "ceil_info = np.array(features[[\"ceil.height0\", \"ceil.height1\", \"ceil.height2\", \"ceil.depth0\",\n",
    "                               \"ceil.depth1\", \"ceil.depth2\",\"ceil.layers\"]])\n",
    "ceil_info = scale(ceil_info, copy=False)\n",
    "\n",
    "# Applying indices retrieved from the best execution to obtain ceil\n",
    "ceil_train, ceil_test, ceil_valid = ceil_info[in_train], ceil_info[in_test], ceil_info[in_valid]\n",
    "\n",
    "# Filtering columns and applying indices retrieved from the best execution to obtain estimators\n",
    "features_estimators = features.drop([\"date\", \"file\", \"camnum\", \"cloud.type\",\"ceil.height0\", \"ceil.height1\",\n",
    "                                     \"ceil.height2\", \"ceil.depth0\",\"ceil.depth1\", \"ceil.depth2\",\"ceil.layers\"], axis=1)\n",
    "\n",
    "features_estimators = pd.DataFrame(scale(features_estimators, copy=False), columns=features_estimators.columns)\n",
    "\n",
    "estimators_train, estimators_test, estimators_valid = features_estimators.iloc[in_train, :], features_estimators.iloc[in_test, :], features_estimators.iloc[in_valid, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of features\n",
    "\n",
    "- **preds_cnn_train, preds_cnn_test, preds_cnn_valid**: predictions of the best CNN model\n",
    "- **estimators_train, estimators_test, estimators_valid**: estimators to train RF classifier\n",
    "- **ceil_train, ceil_test, ceil_valid**: features to combine with outputs of RF and CNN classifiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: RF on estimators classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Experiment 2: RF on estimators classification\n",
    "##############################################################\n",
    "preds_cnn_train_hot = encoder.transform(preds_cnn_train)\n",
    "preds_cnn_valid_hot = encoder.transform(preds_cnn_valid)\n",
    "preds_cnn_test_hot = encoder.transform(preds_cnn_test)\n",
    "\n",
    "experiment_name = \"EXP_2_RF_estimators\"\n",
    "\n",
    "##############################################################\n",
    "# Classic classifiers comparison\n",
    "##############################################################\n",
    "#encoder.inverse_transform(y_train)\n",
    "\n",
    "train_classifiers_on_set(X_train=estimators_train, Y_train=encoder.inverse_transform(y_train), \n",
    "                         X_test=estimators_test, Y_test=encoder.inverse_transform(y_test), \n",
    "                         output_file_id=file_best_exec_id, experiment_name=experiment_name, \n",
    "                         output_dir=plots_dir, encoder=encoder)\n",
    "\n",
    "##############################################################\n",
    "# Training RF with different no. estimators\n",
    "##############################################################\n",
    "\n",
    "\n",
    "preds_estimators_test_RF_hot, preds_estimators_train_RF_hot = grid_search_rf(X_train=estimators_train, Y_train=y_train, X_test=estimators_test, Y_test=y_test,\n",
    "               encoder=encoder, parameters_rf=parameters_rf, file_best_exec_id=file_best_exec_id, experiment_name=experiment_name, output_dir=plots_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Average of RF over estimators + CNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Experiment 3: Average of RF over estimators + CNN predictions\n",
    "##############################################################\n",
    "experiment_name = \"EXP_3_RF_estimators_CNN\"\n",
    "\n",
    "# Test set of classifiers\n",
    "#preds_estimators_test_RF_hot = grid_rf.predict(estimators_test)\n",
    "preds_estimators_test_RF_CNN = encoder.inverse_transform((preds_estimators_test_RF_hot + preds_cnn_test_hot)/2)\n",
    "\n",
    "print(classification_report(y_pred= preds_estimators_test_RF_CNN, y_true= y_test_dec, digits= 3))\n",
    "generate_confusion_matrix_and_report(y_pred=preds_estimators_test_RF_CNN, y_test_dec=y_test_dec, output_file_id=file_best_exec_id, experiment_name=experiment_name, output_dir=plots_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Standard classifiers on CNN predictions + RF over estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Experiment 4: Standard classifiers on CNN predictions + RF over estimators\n",
    "##############################################################\n",
    "experiment_name = \"EXP_4_standard_classifiers_CNN_RF\"\n",
    "print(\"EXPERIMENT %s\" % experiment_name)\n",
    "\n",
    "\n",
    "#preds_estimators_test_RF_hot = grid_rf.predict(estimators_test)\n",
    "#preds_estimators_test_RF = encoder.inverse_transform(preds_estimators_test_RF_hot)\n",
    "\n",
    "x_train_cnn_rf_predictions = np.concatenate((preds_estimators_train_RF_hot, preds_cnn_train_hot, ceil_train), axis=1)\n",
    "x_test_cnn_rf_predictions = np.concatenate((preds_estimators_test_RF_hot, preds_cnn_test_hot, ceil_test), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "train_classifiers_on_set(X_train=x_train_cnn_rf_predictions, Y_train=encoder.inverse_transform(y_train), \n",
    "                         X_test=x_test_cnn_rf_predictions, Y_test=encoder.inverse_transform(y_test), \n",
    "                         output_file_id=file_best_exec_id, experiment_name=experiment_name, output_dir=plots_dir, encoder=encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: Standard classifiers on CNN predictions + RF over estimators + CEIL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"EXP_5_standard_classifiers_ceil_CNN_RF\"\n",
    "\n",
    "#preds_estimators_test_RF_hot = grid_rf.predict(estimators_test)\n",
    "#preds_estimators_test_RF = encoder.inverse_transform(preds_estimators_test_RF_hot)\n",
    "\n",
    "x_train_ceil_cnn_rf_predictions = np.concatenate((preds_estimators_train_RF_hot, preds_cnn_train_hot, ceil_train), axis=1)\n",
    "x_test_ceil_cnn_rf_predictions = np.concatenate((preds_estimators_test_RF_hot, preds_cnn_test_hot, ceil_test), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "train_classifiers_on_set(X_train=x_train_ceil_cnn_rf_predictions, Y_train=encoder.inverse_transform(y_train), \n",
    "                         X_test=x_test_ceil_cnn_rf_predictions, Y_test=encoder.inverse_transform(y_test), \n",
    "                         output_file_id=file_best_exec_id, experiment_name=experiment_name, output_dir=plots_dir, encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
